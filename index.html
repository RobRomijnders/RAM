<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>RAM by RobRomijnders</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>RAM</h1>
        <p>Recurrent models of visual attention</p>

        <p class="view"><a href="https://github.com/RobRomijnders/RAM">View the Project on GitHub <small>RobRomijnders/RAM</small></a></p>


        <ul>
          <li><a href="https://github.com/RobRomijnders/RAM/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/RobRomijnders/RAM/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/RobRomijnders/RAM">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h2>
<a id="recurrent-model-of-visual-attention" class="anchor" href="#recurrent-model-of-visual-attention" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Recurrent model of visual attention</h2>

<p>This post implement the Recurrent model of visual attention paper by <a href="http://arxiv.org/abs/1406.6247">Mnih, 2014</a>. Like the authors, we refer to this algorithm as Recurrent Attention model (RAM).</p>

<h2>
<a id="ram" class="anchor" href="#ram" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>RAM</h2>

<p>The RAM continues the work in attention models for images. Conventional approaches for image classification scale poorly with image size. Humans do not absorb images in a one-shot fashion. We scan the image and attend to part of interest. The RAM models this attention seeking.</p>

<p>Our previous posts treat attention models too. The <a href="https://robromijnders.github.io/DRAW/">DRAW attends to images via Gaussian filters</a>. Another post shows <a href="https://robromijnders.github.io/attention/">three implementations of attention using feature keys</a>. In the RAM paper, the authors observe that humans make decisions on <em>where</em> to look. Next, the eye focuses on a thumb-sizes patch. All other information gets blurred. </p>

<p>These processing forms the basis for RAM. The fovea-like extracts center around a point that conditions on the state of a network. The hidden state of an LSTM maps to a coordinate vector. The corresponding fovea-like extracts inputs to the LSTM at the next time-step.</p>

<p>Our model of the fovea is non-differentiable. The stochasticity in the coordinate-vector allows us to use the REINFORCE rule. For this Reinforcement agent, the reward follows from a correct prediction after a fixed number of time-steps.</p>

<h2>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h2>

<p>The implementation builds upon <a href="https://github.com/seann999/tensorflow_mnist_ram/blob/master/ram.py">this work.</a> Likewise, our visualization resembles his plots.
<img src="https://github.com/RobRomijnders/RAM/blob/master/canvas/RAM_show.gif?raw=true" alt="RAM_gif">
The red squares highlight where the network centers its glimpses. I trained this network on an old laptop for a couple of hours. With more computing power, you might decrease the glimpse-size, allow for more time-steps. Those changes will make the RAM more resemble the human vision system.
The corresponding classification achieves 87% accuracy on MNIST</p>

<p>This results makes us wonder if the attention follows the digit or follow from random perturbations. Therefore, we translate the digits in a larger 60x60 image.
<img src="https://github.com/RobRomijnders/RAM/blob/master/canvas/RAM_translate_show.gif?raw=true" alt="show_translate"></p>

<h2>
<a id="discussion" class="anchor" href="#discussion" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Discussion</h2>

<p>Initially, I learned from <a href="https://github.com/seann999/tensorflow_mnist_ram/blob/master/ram.py">this implementation</a>. This list summarizes my main changes:</p>

<ul>
<li>I changed the reshaping of the sample locations. Sean's implementation incorrectly reshapes the Tensor <em>sampled_locs</em>. The network can still learn. During visualization, however, you'll run into non-trivial transformations.</li>
<li>All linear transformations benefit from an intercept too. I find that biases improve the performance when using linear transformations</li>
<li>Two convolutional layers replace the fully connected layers in the glimpse network. The authors of RAM propose this idea too in their <a href="http://arxiv.org/abs/1412.7755v2">follow-up paper</a>
</li>
<li>I add learning-rate decay. Also the variance of the noise perturbing the sample locations now decays with <em>global_step</em>
</li>
<li>Tensorflow has a quick implementation for Softmax mapping to mutually-exclusive labels. I made this work for this code too.</li>
<li>I re-route the gradient in a crucial way. In Sean's implementation, the reward of the REINFORCE does not backpropagate to the location network. Contratily, the glimpse network does backpropagate into the location network. I add a <em>tf.stop_gradient()</em> such that the glimpse network cannot do this anymore. The reason that REINFORCE does not backpropagate into the location network is that the signals block eachother due to the symmetry in the <em>gaussian_pdf</em> computation. I add another <em>tf.stop_gradient()</em> in this function to prevent this.</li>
</ul>

<p>As always, I am curious to any comments and questions. Reach me at <a href="mailto:romijndersrob@gmail.com">romijndersrob@gmail.com</a></p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/RobRomijnders">RobRomijnders</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
